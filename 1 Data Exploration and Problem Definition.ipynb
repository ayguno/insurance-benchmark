{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing data headers\n",
    "\n",
    "Here we will load and develop initial expectations from the training data. The first step is to clean and add sensible variable headers to be able to describe features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "# Load the tab-delimited training data\n",
    "train_data = pd.read_csv(\"./data/ticdata2000.txt\",\n",
    "                         sep = \"\\t\", header= None)\n",
    "\n",
    "test_data = pd.read_csv(\"./data/ticeval2000.txt\",\n",
    "                        sep = \"\\t\", header = None)\n",
    "# Load data dict, clean to add headers\n",
    "with open(\"./data/dictionary.txt\",\"r\") as f:\n",
    "    line = f.readlines()\n",
    "line_clean = [re.sub(\"\\n|\\...\",\"\",x) for x in line[3:89]]\n",
    "line_clean = [re.sub(\"\\<\",\"less_than_\",x) for x in line_clean]\n",
    "line_clean = [re.sub(\"\\>\",\"higher_than_\",x) for x in line_clean]\n",
    "line_clean = [re.sub(\"\\(|\\)|\\/\",\"\",x) for x in line_clean]\n",
    "line_clean = [re.sub(\"\\-\",\"_\",x) for x in line_clean]\n",
    "line_clean = [re.sub(\"^[0-9]{1} |^[0-9]{2} \",\"\",x) for x in line_clean]\n",
    "line_clean = [re.sub(\" \",\"_\",x) for x in line_clean]\n",
    "line_clean = [re.sub(\"___|__\",\"_\",x) for x in line_clean]\n",
    "line_clean = [re.sub(\"\\_$\",\"\",x) for x in line_clean]\n",
    "\n",
    "train_data.columns = line_clean\n",
    "test_data.columns = line_clean[0:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding categorical features\n",
    "\n",
    "Here our goal is to perform a first pass examination of raw features and determine whether we need to one-hot encode certain categorical variables to be able to interpret them. As we explore these features, we will implement a utility which can process any training/testing data set consistently.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features to one-hot encode\n",
    "categorical_features = ['MOSTYPE_Customer_Subtype_see_L0',\n",
    "                        'MGEMLEEF_Avg_age_see_L1',\n",
    "                        'MOSHOOFD_Customer_main_type_see_L2',\n",
    "                        'MGODRK_Roman_catholic_see_L3',\n",
    "                        'PWAPART_Contribution_private_third_party_insurance_see_L4'\n",
    "                       ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the subset of training data without categorical features\n",
    "train_subset = train_data[[x for x in train_data.columns if x not in categorical_features]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MAANTHUI_Number_of_houses_1_–_10                              [[1, 2, 3, 4, 5, 6, 7, 8, 10]]\n",
       "MGEMOMV_Avg_size_household_1_–_6                                           [[1, 2, 3, 4, 5]]\n",
       "MGODPR_Protestant                                           [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
       "MGODOV_Other_religion                                                   [[0, 1, 2, 3, 4, 5]]\n",
       "MGODGE_No_religion                                          [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
       "MRELGE_Married                                              [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
       "MRELSA_Living_together                                            [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
       "MRELOV_Other_relation                                       [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
       "MFALLEEN_Singles                                            [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
       "MFGEKIND_Household_without_children                         [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
       "MFWEKIND_Household_with_children                            [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
       "MOPLHOOG_High_level_education                               [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
       "MOPLMIDD_Medium_level_education                             [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
       "MOPLLAAG_Lower_level_education                              [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
       "MBERHOOG_High_status                                        [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
       "MBERZELF_Entrepreneur                                                   [[0, 1, 2, 3, 4, 5]]\n",
       "MBERBOER_Farmer                                             [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
       "MBERMIDD_Middle_management                                  [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
       "MBERARBG_Skilled_labourers                                  [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
       "MBERARBO_Unskilled_labourers                                [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
       "MSKA_Social_class_A                                         [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
       "MSKB1_Social_class_B1                                       [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
       "MSKB2_Social_class_B2                                       [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
       "MSKC_Social_class_C                                         [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
       "MSKD_Social_class_D                                            [[0, 1, 2, 3, 4, 5, 6, 7, 9]]\n",
       "MHHUUR_Rented_house                                         [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
       "MHKOOP_Home_owners                                          [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
       "MAUT1_1_car                                                 [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
       "MAUT2_2_cars                                                      [[0, 1, 2, 3, 4, 5, 6, 7]]\n",
       "MAUT0_No_car                                                [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
       "                                                                          ...               \n",
       "PGEZONG_Contribution_family_accidents_insurance_policies                         [[0, 2, 3]]\n",
       "PWAOREG_Contribution_disability_insurance_policies                         [[0, 4, 5, 6, 7]]\n",
       "PBRAND_Contribution_fire_policies                              [[0, 1, 2, 3, 4, 5, 6, 7, 8]]\n",
       "PZEILPL_Contribution_surfboard_policies                                          [[0, 1, 3]]\n",
       "PPLEZIER_Contribution_boat_policies                                  [[0, 1, 2, 3, 4, 5, 6]]\n",
       "PFIETS_Contribution_bicycle_policies                                                [[0, 1]]\n",
       "PINBOED_Contribution_property_insurance_policies                     [[0, 1, 2, 3, 4, 5, 6]]\n",
       "PBYSTAND_Contribution_social_security_insurance_policies                   [[0, 2, 3, 4, 5]]\n",
       "AWAPART_Number_of_private_third_party_insurance_1_12                             [[0, 1, 2]]\n",
       "AWABEDR_Number_of_third_party_insurance_firms                                    [[0, 1, 5]]\n",
       "AWALAND_Number_of_third_party_insurane_agriculture                                  [[0, 1]]\n",
       "APERSAUT_Number_of_car_policies                                      [[0, 1, 2, 3, 4, 6, 7]]\n",
       "ABESAUT_Number_of_delivery_van_policies                                    [[0, 1, 2, 3, 4]]\n",
       "AMOTSCO_Number_of_motorcyclescooter_policies                                  [[0, 1, 2, 8]]\n",
       "AVRAAUT_Number_of_lorry_policies                                              [[0, 1, 2, 3]]\n",
       "AAANHANG_Number_of_trailer_policies                                           [[0, 1, 2, 3]]\n",
       "ATRACTOR_Number_of_tractor_policies                                        [[0, 1, 2, 3, 4]]\n",
       "AWERKT_Number_of_agricultural_machines_policies                            [[0, 1, 2, 3, 6]]\n",
       "ABROM_Number_of_moped_policies                                                   [[0, 1, 2]]\n",
       "ALEVEN_Number_of_life_insurances                                        [[0, 1, 2, 3, 4, 8]]\n",
       "APERSONG_Number_of_private_accident_insurance_policies                              [[0, 1]]\n",
       "AGEZONG_Number_of_family_accidents_insurance_policies                               [[0, 1]]\n",
       "AWAOREG_Number_of_disability_insurance_policies                                  [[0, 1, 2]]\n",
       "ABRAND_Number_of_fire_policies                                       [[0, 1, 2, 3, 4, 5, 7]]\n",
       "AZEILPL_Number_of_surfboard_policies                                                [[0, 1]]\n",
       "APLEZIER_Number_of_boat_policies                                                 [[0, 1, 2]]\n",
       "AFIETS_Number_of_bicycle_policies                                             [[0, 1, 2, 3]]\n",
       "AINBOED_Number_of_property_insurance_policies                                    [[0, 1, 2]]\n",
       "ABYSTAND_Number_of_social_security_insurance_policies                            [[0, 1, 2]]\n",
       "CARAVAN_Number_of_mobile_home_policies_0_1                                          [[0, 1]]\n",
       "Length: 81, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique values of each variable\n",
    "train_subset.apply(axis=0,func= lambda x: [np.unique(x)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we don't have explicit interpretation of any other variables, we will assume they are quantitative (or ordinal) variables (e.g: MBERBOER_Farmer, it is not clear what exactly 0-9 means from the data description)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note we need to convert an otherwise numeric variable to object to be able to use get_dummies\n",
    "train_data_cat = pd.get_dummies(train_data[categorical_features].astype(\"object\"))\n",
    "test_data_cat = pd.get_dummies(test_data[categorical_features].astype(\"object\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep category levels that exist in both data sets\n",
    "keep = [x for x in np.intersect1d(train_data_cat.columns,test_data_cat.columns)]\n",
    "train_data_cat = train_data_cat[keep]\n",
    "test_data_cat = test_data_cat[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace categorical features with original ones\n",
    "train_data = pd.concat([train_data.drop(labels=categorical_features, axis=1),train_data_cat],axis = 1)\n",
    "test_data = pd.concat([test_data.drop(labels=categorical_features, axis=1),test_data_cat],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5822, 150)\n",
      "(4000, 149)\n"
     ]
    }
   ],
   "source": [
    "# Dimensions of the training and test data sets\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialize and store data sets\n",
    "import pickle as pkl\n",
    "with open(\"./data/train_data.pkl\",\"wb\") as f:\n",
    "    pkl.dump(train_data,f)\n",
    "with open(\"./data/test_data.pkl\",\"wb\") as f:\n",
    "    pkl.dump(test_data,f)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the target variable along with features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "with open(\"./data/train_data.pkl\",'rb') as f:\n",
    "    train_data = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5474\n",
       "1     348\n",
       "Name: CARAVAN_Number_of_mobile_home_policies_0_1, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.CARAVAN_Number_of_mobile_home_policies_0_1.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This turns out to be a highly skewed or imbalanced target variable! Are there any features that are strongly associated with having an insuarance policy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal: build marginal logistic regression models with each feature and target\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "models = {} # A dict to hold models that are built\n",
    "y_train = train_data.CARAVAN_Number_of_mobile_home_policies_0_1\n",
    "x_train = train_data.drop('CARAVAN_Number_of_mobile_home_policies_0_1', axis = 1)\n",
    "glm = LogisticRegression(solver='lbfgs')\n",
    "for i in range(1,x_train.shape[1]):\n",
    "    model_name = x_train.columns[i]\n",
    "    models[model_name] = glm.fit(X = x_train.iloc[:,i].values.reshape(-1,1), \n",
    "                                 y = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.72537909]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models['AAANHANG_Number_of_trailer_policies'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 328.011364,
   "position": {
    "height": "40px",
    "left": "1396.45px",
    "right": "20px",
    "top": "138px",
    "width": "354px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
